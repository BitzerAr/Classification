{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import codecs\n",
    "import math\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 16, 8\n",
    "%matplotlib inline\n",
    "nlp = spacy.load('es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>TAG</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Las</td>\n",
       "      <td>DET__Definite=Def|Gender=Fem|Number=Plur|PronT...</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naranjas</td>\n",
       "      <td>NOUN__Gender=Fem|Number=Plur</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>y</td>\n",
       "      <td>CCONJ___</td>\n",
       "      <td>CONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>las</td>\n",
       "      <td>DET__Definite=Def|Gender=Fem|Number=Plur|PronT...</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>manzanas</td>\n",
       "      <td>NOUN__Gender=Fem|Number=Plur</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>se</td>\n",
       "      <td>PRON__Person=3</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>parecen</td>\n",
       "      <td>VERB__Mood=Ind|Number=Plur|Person=3|Tense=Pres...</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Token                                                TAG   POS\n",
       "0       Las  DET__Definite=Def|Gender=Fem|Number=Plur|PronT...   DET\n",
       "1  naranjas                       NOUN__Gender=Fem|Number=Plur  NOUN\n",
       "2         y                                           CCONJ___  CONJ\n",
       "3       las  DET__Definite=Def|Gender=Fem|Number=Plur|PronT...   DET\n",
       "4  manzanas                       NOUN__Gender=Fem|Number=Plur  NOUN\n",
       "5        se                                     PRON__Person=3  PRON\n",
       "6   parecen  VERB__Mood=Ind|Number=Plur|Person=3|Tense=Pres...  VERB"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('Las naranjas y las manzanas se parecen')\n",
    "pd.DataFrame([[word.text, word.tag_, word.pos_] for word in doc], columns=['Token', 'TAG', 'POS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Log Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Las</td>\n",
       "      <td>2.061154e-09</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naranjas</td>\n",
       "      <td>2.061154e-09</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>y</td>\n",
       "      <td>2.061154e-09</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>las</td>\n",
       "      <td>2.061154e-09</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>manzanas</td>\n",
       "      <td>2.061154e-09</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>se</td>\n",
       "      <td>2.061154e-09</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>parecen</td>\n",
       "      <td>2.061154e-09</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Token          Prob  Log Prob\n",
       "0       Las  2.061154e-09     -20.0\n",
       "1  naranjas  2.061154e-09     -20.0\n",
       "2         y  2.061154e-09     -20.0\n",
       "3       las  2.061154e-09     -20.0\n",
       "4  manzanas  2.061154e-09     -20.0\n",
       "5        se  2.061154e-09     -20.0\n",
       "6   parecen  2.061154e-09     -20.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([[word.text, math.exp(word.prob), word.prob] for word in doc], columns=['Token', 'Prob', 'Log Prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angela Merkel \t PER\n",
      "Buenos Aires \t LOC\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"La premier alemana Angela Merkel visit√≥ Buenos Aires esta semana\")\n",
    "for ent in doc2.ents:\n",
    "    print('{} \\t {}'.format(ent, ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7135406"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orange = doc[1]\n",
    "apple = doc[4]\n",
    "orange.similarity(apple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/susanli2016/Machine-Learning-with-Python/master/research_paper.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title         0\n",
       "Conference    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research title sample: Cooperating with Smartness: Using Heterogeneous Smart Antennas in Ad-Hoc Networks.\n",
      "Conference of this paper: INFOCOM\n",
      "Training Data Shape: (1679, 2)\n",
      "Testing Data Shape: (828, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.33, random_state=42)\n",
    "print('Research title sample:', train['Title'].iloc[0])\n",
    "print('Conference of this paper:', train['Conference'].iloc[0])\n",
    "print('Training Data Shape:', train.shape)\n",
    "print('Testing Data Shape:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'sample_esp_fixed.txt'  \n",
    "a= []\n",
    "with open(filepath) as fp:  \n",
    "    line = fp.readline()\n",
    "    cnt = 1\n",
    "    while line:\n",
    "        #print(\"Line {}: {}\".format(cnt, line.strip()))\n",
    "        line = fp.readline()\n",
    "        cnt += 1\n",
    "        a.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [item.split('?')[0] for item in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['¬øCu√°ntas patas tiene una ara√±a',\n",
       " '¬øCu√°l es el r√≠o m√°s caudaloso del mundo',\n",
       " '¬øCada cu√°ntos a√±os tenemos un a√±o bisiesto',\n",
       " '¬øCu√°ntos meses tienen 28 d√≠as',\n",
       " '¬øQu√© es un siglo',\n",
       " '¬øQui√©n fue Cleopatra',\n",
       " '¬øQu√© planeta es el m√°s cercano al Sol',\n",
       " '¬øCu√°l es la monta√±a m√°s alta en la actualidad',\n",
       " '¬øQue nombre tiene el sonido que hace una oveja',\n",
       " '¬øEn qu√© ciudad y en qu√© pa√≠s se encuentra la Torre Eiffel',\n",
       " '¬øPara qu√© sirven las arterias y las venas',\n",
       " '¬øQu√© es un delta',\n",
       " 'Si alguien de Espa√±a habla espa√±ol, alguien de Portugal portugu√©s y alguien de Francia franc√©s. ¬øQu√© habla alguien de Brasil',\n",
       " '¬øQu√© huesos encontramos en el antebrazo',\n",
       " '¬øQu√© tipo de palabra es \"aqu√≠\"',\n",
       " '¬øQu√© quiere decir que un tri√°ngulo sea is√≥celes',\n",
       " 'Si decimos que estamos en el XIX/XI/MMXVIII, ¬øde qu√© fecha estamos hablando',\n",
       " '¬øQu√© es un mam√≠fero',\n",
       " '¬øCu√°les son los cinco continentes',\n",
       " '¬øCu√°ndo termina la Edad Antigua',\n",
       " '¬øCu√°les son los estados de la materia',\n",
       " '¬øA qu√© temperatura se congela el agua',\n",
       " '¬øQui√©n es tu primo',\n",
       " '¬øCu√°l es el personaje m√°s conocido de Miguel de Cervantes',\n",
       " '¬øPara qu√© sirve un adjetivo',\n",
       " 'En m√∫sica, ¬øA cu√°ntos tiempos equivale una blanca',\n",
       " '¬øCu√°l es el pa√≠s con mayor poblaci√≥n del mundo',\n",
       " '¬øCu√°les son los principales sectores econ√≥micos',\n",
       " '¬øCu√°ntas s√≠labas tiene la palabra abecedario',\n",
       " '¬øQu√© significa que dos palabras sean sin√≥nimos',\n",
       " '¬øQu√© tipo de instrumento es un piano',\n",
       " '¬øCu√°l es la s√≠laba t√≥nica de la palabra amanecer',\n",
       " '¬øQu√© son los montes Urales',\n",
       " '¬øC√≥mo se llamaban las tres carabelas que fueron a Am√©rica con Crist√≥bal Col√≥n',\n",
       " '¬øCu√°nto suman los √°ngulos de un tri√°ngulo',\n",
       " 'Si tengo 25 manzanas y le doy a mi mejor amigo el 25% de ellas. ¬øCu√°ntas manzanas le he dado',\n",
       " '¬øCu√°les son los planetas del sistema solar',\n",
       " '¬øEn qu√© reinos clasificamos los seres vivos',\n",
       " '¬øQu√© quiere decir que una palabra sea esdr√∫jula',\n",
       " 'Si en una carrera adelanto al que va segundo',\n",
       " '¬øCu√°les son los tres modos verbales',\n",
       " '¬øQu√© es un n√∫mero primo',\n",
       " '¬øCu√°ntos kilos son una tonelada',\n",
       " '¬øC√≥mo se llaman los huesecillos del o√≠do en los cuales el sonido rebota hasta llegar a la c√≥clea',\n",
       " '¬øCu√°l es la capital de Italia',\n",
       " '¬øCada cu√°ntos lustros pasa un siglo',\n",
       " '¬øQu√© es el complemento indirecto',\n",
       " 'En un texto narrativo, ¬øc√≥mo se denomina al personaje principal',\n",
       " '¬øQui√©n pint√≥ la Mona Lisa',\n",
       " '']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist] for document in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cuantas', 'patas', 'tiene', 'una', 'arana'],\n",
       " ['cual', 'es', 'el', 'rio', 'mas', 'caudaloso', 'del', 'mundo'],\n",
       " ['cada', 'cuantos', 'anos', 'tenemos', 'un', 'ano', 'bisiesto'],\n",
       " ['cuantos', 'meses', 'tienen', '28', 'dias'],\n",
       " ['que', 'es', 'un', 'siglo'],\n",
       " ['quien', 'fue', 'cleopatra'],\n",
       " ['que', 'planeta', 'es', 'el', 'mas', 'cercano', 'al', 'sol'],\n",
       " ['cual', 'es', 'la', 'montana', 'mas', 'alta', 'en', 'la', 'actualidad'],\n",
       " ['que', 'nombre', 'tiene', 'el', 'sonido', 'que', 'hace', 'una', 'oveja'],\n",
       " ['en',\n",
       "  'que',\n",
       "  'ciudad',\n",
       "  'y',\n",
       "  'en',\n",
       "  'que',\n",
       "  'pais',\n",
       "  'se',\n",
       "  'encuentra',\n",
       "  'la',\n",
       "  'torre',\n",
       "  'eiffel'],\n",
       " ['para', 'que', 'sirven', 'las', 'arterias', 'y', 'las', 'venas'],\n",
       " ['que', 'es', 'un', 'delta'],\n",
       " ['si',\n",
       "  'alguien',\n",
       "  'de',\n",
       "  'espana',\n",
       "  'habla',\n",
       "  'espanol,',\n",
       "  'alguien',\n",
       "  'de',\n",
       "  'portugal',\n",
       "  'portugues',\n",
       "  'y',\n",
       "  'alguien',\n",
       "  'de',\n",
       "  'francia',\n",
       "  'frances.',\n",
       "  'que',\n",
       "  'habla',\n",
       "  'alguien',\n",
       "  'de',\n",
       "  'brasil'],\n",
       " ['que', 'huesos', 'encontramos', 'en', 'el', 'antebrazo'],\n",
       " ['que', 'tipo', 'de', 'palabra', 'es', 'aqui'],\n",
       " ['que', 'quiere', 'decir', 'que', 'un', 'triangulo', 'sea', 'isosceles'],\n",
       " ['si',\n",
       "  'decimos',\n",
       "  'que',\n",
       "  'estamos',\n",
       "  'en',\n",
       "  'el',\n",
       "  'xix/xi/mmxviii,',\n",
       "  'de',\n",
       "  'que',\n",
       "  'fecha',\n",
       "  'estamos',\n",
       "  'hablando'],\n",
       " ['que', 'es', 'un', 'mamifero'],\n",
       " ['cuales', 'son', 'los', 'cinco', 'continentes'],\n",
       " ['cuando', 'termina', 'la', 'edad', 'antigua'],\n",
       " ['cuales', 'son', 'los', 'estados', 'de', 'la', 'materia'],\n",
       " ['que', 'temperatura', 'se', 'congela', 'el', 'agua'],\n",
       " ['quien', 'es', 'tu', 'primo'],\n",
       " ['cual',\n",
       "  'es',\n",
       "  'el',\n",
       "  'personaje',\n",
       "  'mas',\n",
       "  'conocido',\n",
       "  'de',\n",
       "  'miguel',\n",
       "  'de',\n",
       "  'cervantes'],\n",
       " ['para', 'que', 'sirve', 'un', 'adjetivo'],\n",
       " ['en', 'musica,', 'cuantos', 'tiempos', 'equivale', 'una', 'blanca'],\n",
       " ['cual', 'es', 'el', 'pais', 'con', 'mayor', 'poblacion', 'del', 'mundo'],\n",
       " ['cuales', 'son', 'los', 'principales', 'sectores', 'economicos'],\n",
       " ['cuantas', 'silabas', 'tiene', 'la', 'palabra', 'abecedario'],\n",
       " ['que', 'significa', 'que', 'dos', 'palabras', 'sean', 'sinonimos'],\n",
       " ['que', 'tipo', 'de', 'instrumento', 'es', 'un', 'piano'],\n",
       " ['cual', 'es', 'la', 'silaba', 'tonica', 'de', 'la', 'palabra', 'amanecer'],\n",
       " ['que', 'son', 'los', 'montes', 'urales'],\n",
       " ['como',\n",
       "  'se',\n",
       "  'llamaban',\n",
       "  'las',\n",
       "  'tres',\n",
       "  'carabelas',\n",
       "  'que',\n",
       "  'fueron',\n",
       "  'america',\n",
       "  'con',\n",
       "  'cristobal',\n",
       "  'colon'],\n",
       " ['cuanto', 'suman', 'los', 'angulos', 'de', 'un', 'triangulo'],\n",
       " ['si',\n",
       "  'tengo',\n",
       "  '25',\n",
       "  'manzanas',\n",
       "  'y',\n",
       "  'le',\n",
       "  'doy',\n",
       "  'mi',\n",
       "  'mejor',\n",
       "  'amigo',\n",
       "  'el',\n",
       "  '25%',\n",
       "  'de',\n",
       "  'ellas.',\n",
       "  'cuantas',\n",
       "  'manzanas',\n",
       "  'le',\n",
       "  'he',\n",
       "  'dado'],\n",
       " ['cuales', 'son', 'los', 'planetas', 'del', 'sistema', 'solar'],\n",
       " ['en', 'que', 'reinos', 'clasificamos', 'los', 'seres', 'vivos'],\n",
       " ['que', 'quiere', 'decir', 'que', 'una', 'palabra', 'sea', 'esdrujula'],\n",
       " ['si',\n",
       "  'en',\n",
       "  'una',\n",
       "  'carrera',\n",
       "  'adelanto',\n",
       "  'al',\n",
       "  'que',\n",
       "  'va',\n",
       "  'segundo',\n",
       "  '85',\n",
       "  'en',\n",
       "  'que',\n",
       "  'posicion',\n",
       "  'estaba',\n",
       "  'antes',\n",
       "  'y',\n",
       "  'en',\n",
       "  'cual',\n",
       "  'estoy',\n",
       "  'ahora'],\n",
       " ['cuales', 'son', 'los', 'tres', 'modos', 'verbales'],\n",
       " ['que', 'es', 'un', 'numero', 'primo'],\n",
       " ['cuantos', 'kilos', 'son', 'una', 'tonelada'],\n",
       " ['como',\n",
       "  'se',\n",
       "  'llaman',\n",
       "  'los',\n",
       "  'huesecillos',\n",
       "  'del',\n",
       "  'oido',\n",
       "  'en',\n",
       "  'los',\n",
       "  'cuales',\n",
       "  'el',\n",
       "  'sonido',\n",
       "  'rebota',\n",
       "  'hasta',\n",
       "  'llegar',\n",
       "  'la',\n",
       "  'coclea'],\n",
       " ['cual', 'es', 'la', 'capital', 'de', 'italia'],\n",
       " ['cada', 'cuantos', 'lustros', 'pasa', 'un', 'siglo'],\n",
       " ['que', 'es', 'el', 'complemento', 'indirecto'],\n",
       " ['en',\n",
       "  'un',\n",
       "  'texto',\n",
       "  'narrativo,',\n",
       "  'como',\n",
       "  'se',\n",
       "  'denomina',\n",
       "  'al',\n",
       "  'personaje',\n",
       "  'principal'],\n",
       " ['quien', 'pinto', 'la', 'mona', 'lisa'],\n",
       " []]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuantas\n",
      "tiene\n",
      "una\n",
      "cual\n",
      "es\n",
      "el\n",
      "mas\n",
      "del\n",
      "mundo\n",
      "cada\n",
      "cuantos\n",
      "un\n",
      "cuantos\n",
      "que\n",
      "es\n",
      "un\n",
      "siglo\n",
      "quien\n",
      "que\n",
      "es\n",
      "el\n",
      "mas\n",
      "al\n",
      "cual\n",
      "es\n",
      "la\n",
      "mas\n",
      "en\n",
      "la\n",
      "que\n",
      "tiene\n",
      "el\n",
      "sonido\n",
      "que\n",
      "una\n",
      "en\n",
      "que\n",
      "y\n",
      "en\n",
      "que\n",
      "pais\n",
      "se\n",
      "la\n",
      "para\n",
      "que\n",
      "las\n",
      "y\n",
      "las\n",
      "que\n",
      "es\n",
      "un\n",
      "si\n",
      "alguien\n",
      "de\n",
      "habla\n",
      "alguien\n",
      "de\n",
      "y\n",
      "alguien\n",
      "de\n",
      "que\n",
      "habla\n",
      "alguien\n",
      "de\n",
      "que\n",
      "en\n",
      "el\n",
      "que\n",
      "tipo\n",
      "de\n",
      "palabra\n",
      "es\n",
      "que\n",
      "quiere\n",
      "decir\n",
      "que\n",
      "un\n",
      "triangulo\n",
      "sea\n",
      "si\n",
      "que\n",
      "estamos\n",
      "en\n",
      "el\n",
      "de\n",
      "que\n",
      "estamos\n",
      "que\n",
      "es\n",
      "un\n",
      "cuales\n",
      "son\n",
      "los\n",
      "la\n",
      "cuales\n",
      "son\n",
      "los\n",
      "de\n",
      "la\n",
      "que\n",
      "se\n",
      "el\n",
      "quien\n",
      "es\n",
      "primo\n",
      "cual\n",
      "es\n",
      "el\n",
      "personaje\n",
      "mas\n",
      "de\n",
      "de\n",
      "para\n",
      "que\n",
      "un\n",
      "en\n",
      "cuantos\n",
      "una\n",
      "cual\n",
      "es\n",
      "el\n",
      "pais\n",
      "con\n",
      "del\n",
      "mundo\n",
      "cuales\n",
      "son\n",
      "los\n",
      "cuantas\n",
      "tiene\n",
      "la\n",
      "palabra\n",
      "que\n",
      "que\n",
      "que\n",
      "tipo\n",
      "de\n",
      "es\n",
      "un\n",
      "cual\n",
      "es\n",
      "la\n",
      "de\n",
      "la\n",
      "palabra\n",
      "que\n",
      "son\n",
      "los\n",
      "como\n",
      "se\n",
      "las\n",
      "tres\n",
      "que\n",
      "con\n",
      "los\n",
      "de\n",
      "un\n",
      "triangulo\n",
      "si\n",
      "manzanas\n",
      "y\n",
      "le\n",
      "el\n",
      "de\n",
      "cuantas\n",
      "manzanas\n",
      "le\n",
      "cuales\n",
      "son\n",
      "los\n",
      "del\n",
      "en\n",
      "que\n",
      "los\n",
      "que\n",
      "quiere\n",
      "decir\n",
      "que\n",
      "una\n",
      "palabra\n",
      "sea\n",
      "si\n",
      "en\n",
      "una\n",
      "al\n",
      "que\n",
      "en\n",
      "que\n",
      "y\n",
      "en\n",
      "cual\n",
      "cuales\n",
      "son\n",
      "los\n",
      "tres\n",
      "que\n",
      "es\n",
      "un\n",
      "primo\n",
      "cuantos\n",
      "son\n",
      "una\n",
      "como\n",
      "se\n",
      "los\n",
      "del\n",
      "en\n",
      "los\n",
      "cuales\n",
      "el\n",
      "sonido\n",
      "la\n",
      "cual\n",
      "es\n",
      "la\n",
      "de\n",
      "cada\n",
      "cuantos\n",
      "un\n",
      "siglo\n",
      "que\n",
      "es\n",
      "el\n",
      "en\n",
      "un\n",
      "como\n",
      "se\n",
      "al\n",
      "personaje\n",
      "quien\n",
      "la\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    for token in text:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'cuantas': 3,\n",
       "             'patas': 1,\n",
       "             'tiene': 3,\n",
       "             'una': 6,\n",
       "             'arana': 1,\n",
       "             'cual': 7,\n",
       "             'es': 15,\n",
       "             'el': 11,\n",
       "             'rio': 1,\n",
       "             'mas': 4,\n",
       "             'caudaloso': 1,\n",
       "             'del': 4,\n",
       "             'mundo': 2,\n",
       "             'cada': 2,\n",
       "             'cuantos': 5,\n",
       "             'anos': 1,\n",
       "             'tenemos': 1,\n",
       "             'un': 11,\n",
       "             'ano': 1,\n",
       "             'bisiesto': 1,\n",
       "             'meses': 1,\n",
       "             'tienen': 1,\n",
       "             '28': 1,\n",
       "             'dias': 1,\n",
       "             'que': 30,\n",
       "             'siglo': 2,\n",
       "             'quien': 3,\n",
       "             'fue': 1,\n",
       "             'cleopatra': 1,\n",
       "             'planeta': 1,\n",
       "             'cercano': 1,\n",
       "             'al': 3,\n",
       "             'sol': 1,\n",
       "             'la': 11,\n",
       "             'montana': 1,\n",
       "             'alta': 1,\n",
       "             'en': 12,\n",
       "             'actualidad': 1,\n",
       "             'nombre': 1,\n",
       "             'sonido': 2,\n",
       "             'hace': 1,\n",
       "             'oveja': 1,\n",
       "             'ciudad': 1,\n",
       "             'y': 5,\n",
       "             'pais': 2,\n",
       "             'se': 5,\n",
       "             'encuentra': 1,\n",
       "             'torre': 1,\n",
       "             'eiffel': 1,\n",
       "             'para': 2,\n",
       "             'sirven': 1,\n",
       "             'las': 3,\n",
       "             'arterias': 1,\n",
       "             'venas': 1,\n",
       "             'delta': 1,\n",
       "             'si': 4,\n",
       "             'alguien': 4,\n",
       "             'de': 14,\n",
       "             'espana': 1,\n",
       "             'habla': 2,\n",
       "             'espanol,': 1,\n",
       "             'portugal': 1,\n",
       "             'portugues': 1,\n",
       "             'francia': 1,\n",
       "             'frances.': 1,\n",
       "             'brasil': 1,\n",
       "             'huesos': 1,\n",
       "             'encontramos': 1,\n",
       "             'antebrazo': 1,\n",
       "             'tipo': 2,\n",
       "             'palabra': 4,\n",
       "             'aqui': 1,\n",
       "             'quiere': 2,\n",
       "             'decir': 2,\n",
       "             'triangulo': 2,\n",
       "             'sea': 2,\n",
       "             'isosceles': 1,\n",
       "             'decimos': 1,\n",
       "             'estamos': 2,\n",
       "             'xix/xi/mmxviii,': 1,\n",
       "             'fecha': 1,\n",
       "             'hablando': 1,\n",
       "             'mamifero': 1,\n",
       "             'cuales': 6,\n",
       "             'son': 7,\n",
       "             'los': 10,\n",
       "             'cinco': 1,\n",
       "             'continentes': 1,\n",
       "             'cuando': 1,\n",
       "             'termina': 1,\n",
       "             'edad': 1,\n",
       "             'antigua': 1,\n",
       "             'estados': 1,\n",
       "             'materia': 1,\n",
       "             'temperatura': 1,\n",
       "             'congela': 1,\n",
       "             'agua': 1,\n",
       "             'tu': 1,\n",
       "             'primo': 2,\n",
       "             'personaje': 2,\n",
       "             'conocido': 1,\n",
       "             'miguel': 1,\n",
       "             'cervantes': 1,\n",
       "             'sirve': 1,\n",
       "             'adjetivo': 1,\n",
       "             'musica,': 1,\n",
       "             'tiempos': 1,\n",
       "             'equivale': 1,\n",
       "             'blanca': 1,\n",
       "             'con': 2,\n",
       "             'mayor': 1,\n",
       "             'poblacion': 1,\n",
       "             'principales': 1,\n",
       "             'sectores': 1,\n",
       "             'economicos': 1,\n",
       "             'silabas': 1,\n",
       "             'abecedario': 1,\n",
       "             'significa': 1,\n",
       "             'dos': 1,\n",
       "             'palabras': 1,\n",
       "             'sean': 1,\n",
       "             'sinonimos': 1,\n",
       "             'instrumento': 1,\n",
       "             'piano': 1,\n",
       "             'silaba': 1,\n",
       "             'tonica': 1,\n",
       "             'amanecer': 1,\n",
       "             'montes': 1,\n",
       "             'urales': 1,\n",
       "             'como': 3,\n",
       "             'llamaban': 1,\n",
       "             'tres': 2,\n",
       "             'carabelas': 1,\n",
       "             'fueron': 1,\n",
       "             'america': 1,\n",
       "             'cristobal': 1,\n",
       "             'colon': 1,\n",
       "             'cuanto': 1,\n",
       "             'suman': 1,\n",
       "             'angulos': 1,\n",
       "             'tengo': 1,\n",
       "             '25': 1,\n",
       "             'manzanas': 2,\n",
       "             'le': 2,\n",
       "             'doy': 1,\n",
       "             'mi': 1,\n",
       "             'mejor': 1,\n",
       "             'amigo': 1,\n",
       "             '25%': 1,\n",
       "             'ellas.': 1,\n",
       "             'he': 1,\n",
       "             'dado': 1,\n",
       "             'planetas': 1,\n",
       "             'sistema': 1,\n",
       "             'solar': 1,\n",
       "             'reinos': 1,\n",
       "             'clasificamos': 1,\n",
       "             'seres': 1,\n",
       "             'vivos': 1,\n",
       "             'esdrujula': 1,\n",
       "             'carrera': 1,\n",
       "             'adelanto': 1,\n",
       "             'va': 1,\n",
       "             'segundo': 1,\n",
       "             '85': 1,\n",
       "             'posicion': 1,\n",
       "             'estaba': 1,\n",
       "             'antes': 1,\n",
       "             'estoy': 1,\n",
       "             'ahora': 1,\n",
       "             'modos': 1,\n",
       "             'verbales': 1,\n",
       "             'numero': 1,\n",
       "             'kilos': 1,\n",
       "             'tonelada': 1,\n",
       "             'llaman': 1,\n",
       "             'huesecillos': 1,\n",
       "             'oido': 1,\n",
       "             'rebota': 1,\n",
       "             'hasta': 1,\n",
       "             'llegar': 1,\n",
       "             'coclea': 1,\n",
       "             'capital': 1,\n",
       "             'italia': 1,\n",
       "             'lustros': 1,\n",
       "             'pasa': 1,\n",
       "             'complemento': 1,\n",
       "             'indirecto': 1,\n",
       "             'texto': 1,\n",
       "             'narrativo,': 1,\n",
       "             'denomina': 1,\n",
       "             'principal': 1,\n",
       "             'pinto': 1,\n",
       "             'mona': 1,\n",
       "             'lisa': 1})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [[token for token in text if frequency[token] > 1] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cuantas', 'tiene', 'una'],\n",
       " ['cual', 'es', 'el', 'mas', 'del', 'mundo'],\n",
       " ['cada', 'cuantos', 'un'],\n",
       " ['cuantos'],\n",
       " ['que', 'es', 'un', 'siglo'],\n",
       " ['quien'],\n",
       " ['que', 'es', 'el', 'mas', 'al'],\n",
       " ['cual', 'es', 'la', 'mas', 'en', 'la'],\n",
       " ['que', 'tiene', 'el', 'sonido', 'que', 'una'],\n",
       " ['en', 'que', 'y', 'en', 'que', 'pais', 'se', 'la'],\n",
       " ['para', 'que', 'las', 'y', 'las'],\n",
       " ['que', 'es', 'un'],\n",
       " ['si',\n",
       "  'alguien',\n",
       "  'de',\n",
       "  'habla',\n",
       "  'alguien',\n",
       "  'de',\n",
       "  'y',\n",
       "  'alguien',\n",
       "  'de',\n",
       "  'que',\n",
       "  'habla',\n",
       "  'alguien',\n",
       "  'de'],\n",
       " ['que', 'en', 'el'],\n",
       " ['que', 'tipo', 'de', 'palabra', 'es'],\n",
       " ['que', 'quiere', 'decir', 'que', 'un', 'triangulo', 'sea'],\n",
       " ['si', 'que', 'estamos', 'en', 'el', 'de', 'que', 'estamos'],\n",
       " ['que', 'es', 'un'],\n",
       " ['cuales', 'son', 'los'],\n",
       " ['la'],\n",
       " ['cuales', 'son', 'los', 'de', 'la'],\n",
       " ['que', 'se', 'el'],\n",
       " ['quien', 'es', 'primo'],\n",
       " ['cual', 'es', 'el', 'personaje', 'mas', 'de', 'de'],\n",
       " ['para', 'que', 'un'],\n",
       " ['en', 'cuantos', 'una'],\n",
       " ['cual', 'es', 'el', 'pais', 'con', 'del', 'mundo'],\n",
       " ['cuales', 'son', 'los'],\n",
       " ['cuantas', 'tiene', 'la', 'palabra'],\n",
       " ['que', 'que'],\n",
       " ['que', 'tipo', 'de', 'es', 'un'],\n",
       " ['cual', 'es', 'la', 'de', 'la', 'palabra'],\n",
       " ['que', 'son', 'los'],\n",
       " ['como', 'se', 'las', 'tres', 'que', 'con'],\n",
       " ['los', 'de', 'un', 'triangulo'],\n",
       " ['si', 'manzanas', 'y', 'le', 'el', 'de', 'cuantas', 'manzanas', 'le'],\n",
       " ['cuales', 'son', 'los', 'del'],\n",
       " ['en', 'que', 'los'],\n",
       " ['que', 'quiere', 'decir', 'que', 'una', 'palabra', 'sea'],\n",
       " ['si', 'en', 'una', 'al', 'que', 'en', 'que', 'y', 'en', 'cual'],\n",
       " ['cuales', 'son', 'los', 'tres'],\n",
       " ['que', 'es', 'un', 'primo'],\n",
       " ['cuantos', 'son', 'una'],\n",
       " ['como', 'se', 'los', 'del', 'en', 'los', 'cuales', 'el', 'sonido', 'la'],\n",
       " ['cual', 'es', 'la', 'de'],\n",
       " ['cada', 'cuantos', 'un', 'siglo'],\n",
       " ['que', 'es', 'el'],\n",
       " ['en', 'un', 'como', 'se', 'al', 'personaje'],\n",
       " ['quien', 'la'],\n",
       " []]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(45 unique tokens: ['cuantas', 'tiene', 'una', 'cual', 'del']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuantas': 0, 'tiene': 1, 'una': 2, 'cual': 3, 'del': 4, 'el': 5, 'es': 6, 'mas': 7, 'mundo': 8, 'cada': 9, 'cuantos': 10, 'un': 11, 'que': 12, 'siglo': 13, 'quien': 14, 'al': 15, 'en': 16, 'la': 17, 'sonido': 18, 'pais': 19, 'se': 20, 'y': 21, 'las': 22, 'para': 23, 'alguien': 24, 'de': 25, 'habla': 26, 'si': 27, 'palabra': 28, 'tipo': 29, 'decir': 30, 'quiere': 31, 'sea': 32, 'triangulo': 33, 'estamos': 34, 'cuales': 35, 'los': 36, 'son': 37, 'primo': 38, 'personaje': 39, 'con': 40, 'como': 41, 'tres': 42, 'le': 43, 'manzanas': 44}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)],\n",
       " [(9, 1), (10, 1), (11, 1)],\n",
       " [(10, 1)],\n",
       " [(6, 1), (11, 1), (12, 1), (13, 1)],\n",
       " [(14, 1)],\n",
       " [(5, 1), (6, 1), (7, 1), (12, 1), (15, 1)],\n",
       " [(3, 1), (6, 1), (7, 1), (16, 1), (17, 2)],\n",
       " [(1, 1), (2, 1), (5, 1), (12, 2), (18, 1)],\n",
       " [(12, 2), (16, 2), (17, 1), (19, 1), (20, 1), (21, 1)],\n",
       " [(12, 1), (21, 1), (22, 2), (23, 1)],\n",
       " [(6, 1), (11, 1), (12, 1)],\n",
       " [(12, 1), (21, 1), (24, 4), (25, 4), (26, 2), (27, 1)],\n",
       " [(5, 1), (12, 1), (16, 1)],\n",
       " [(6, 1), (12, 1), (25, 1), (28, 1), (29, 1)],\n",
       " [(11, 1), (12, 2), (30, 1), (31, 1), (32, 1), (33, 1)],\n",
       " [(5, 1), (12, 2), (16, 1), (25, 1), (27, 1), (34, 2)],\n",
       " [(6, 1), (11, 1), (12, 1)],\n",
       " [(35, 1), (36, 1), (37, 1)],\n",
       " [(17, 1)],\n",
       " [(17, 1), (25, 1), (35, 1), (36, 1), (37, 1)],\n",
       " [(5, 1), (12, 1), (20, 1)],\n",
       " [(6, 1), (14, 1), (38, 1)],\n",
       " [(3, 1), (5, 1), (6, 1), (7, 1), (25, 2), (39, 1)],\n",
       " [(11, 1), (12, 1), (23, 1)],\n",
       " [(2, 1), (10, 1), (16, 1)],\n",
       " [(3, 1), (4, 1), (5, 1), (6, 1), (8, 1), (19, 1), (40, 1)],\n",
       " [(35, 1), (36, 1), (37, 1)],\n",
       " [(0, 1), (1, 1), (17, 1), (28, 1)],\n",
       " [(12, 2)],\n",
       " [(6, 1), (11, 1), (12, 1), (25, 1), (29, 1)],\n",
       " [(3, 1), (6, 1), (17, 2), (25, 1), (28, 1)],\n",
       " [(12, 1), (36, 1), (37, 1)],\n",
       " [(12, 1), (20, 1), (22, 1), (40, 1), (41, 1), (42, 1)],\n",
       " [(11, 1), (25, 1), (33, 1), (36, 1)],\n",
       " [(0, 1), (5, 1), (21, 1), (25, 1), (27, 1), (43, 2), (44, 2)],\n",
       " [(4, 1), (35, 1), (36, 1), (37, 1)],\n",
       " [(12, 1), (16, 1), (36, 1)],\n",
       " [(2, 1), (12, 2), (28, 1), (30, 1), (31, 1), (32, 1)],\n",
       " [(2, 1), (3, 1), (12, 2), (15, 1), (16, 3), (21, 1), (27, 1)],\n",
       " [(35, 1), (36, 1), (37, 1), (42, 1)],\n",
       " [(6, 1), (11, 1), (12, 1), (38, 1)],\n",
       " [(2, 1), (10, 1), (37, 1)],\n",
       " [(4, 1),\n",
       "  (5, 1),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 1),\n",
       "  (20, 1),\n",
       "  (35, 1),\n",
       "  (36, 2),\n",
       "  (41, 1)],\n",
       " [(3, 1), (6, 1), (17, 1), (25, 1)],\n",
       " [(9, 1), (10, 1), (11, 1), (13, 1)],\n",
       " [(5, 1), (6, 1), (12, 1)],\n",
       " [(11, 1), (15, 1), (16, 1), (20, 1), (39, 1), (41, 1)],\n",
       " [(14, 1), (17, 1)],\n",
       " []]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 0.3546866103990365), (4, 0.45564125616376666), (5, 0.2731485283039088), (6, 0.2171966027254392), (7, 0.45564125616376666), (8, 0.5806849550458391)]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf[corpus[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = \"patas arana\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = dictionary.doc2bow(vec.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = index[tfidf[corpus[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = \"cuantas veces quiere\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vec = dictionary.doc2bow(new.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sustantivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visited = {}\n",
    "nouns = []\n",
    "for word in corpus:\n",
    "    if word.pos_.startswith('N') and len(word.string) < 25:\n",
    "        token = word.string.strip().lower()\n",
    "        if token in visited:\n",
    "            visited[token] += 1\n",
    "            continue\n",
    "        else:\n",
    "            visited[token] = 1\n",
    "            nouns.append(word)\n",
    "nouns = sorted(nouns, key=lambda w: -visited[w.string.strip().lower()])[:150]\n",
    "df = pd.DataFrame([[w.text, visited[w.string.strip().lower()]] for w in nouns], columns=['Noun', 'Freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Freq > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visited = {}\n",
    "nouns = []\n",
    "for word in corpus:\n",
    "    if word.pos_.startswith('V') and len(word.string) < 25:\n",
    "        token = word.string.strip().lower()\n",
    "        if token in visited:\n",
    "            visited[token] += 1\n",
    "            continue\n",
    "        else:\n",
    "            visited[token] = 1\n",
    "            nouns.append(word)\n",
    "nouns = sorted(nouns, key=lambda w: -visited[w.string.strip().lower()])[:150]\n",
    "df_V = pd.DataFrame([[w.text, visited[w.string.strip().lower()]] for w in nouns], columns=['Noun', 'Freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_V = df_V[df_V.Freq > 1]\n",
    "df_V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visited = {}\n",
    "nouns = []\n",
    "for word in corpus:\n",
    "    if word.pos_.startswith('ADJ') and len(word.string) < 25:\n",
    "        token = word.string.strip().lower()\n",
    "        if token in visited:\n",
    "            visited[token] += 1\n",
    "            continue\n",
    "        else:\n",
    "            visited[token] = 1\n",
    "            nouns.append(word)\n",
    "nouns = sorted(nouns, key=lambda w: -visited[w.string.strip().lower()])[:150]\n",
    "df_adj = pd.DataFrame([[w.text, visited[w.string.strip().lower()]] for w in nouns], columns=['Noun', 'Freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_termcounts = vectorizer.fit_transform(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_termcounts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([[word.text, word.tag_, word.pos_] for word in doc], columns=['Token', 'TAG', 'POS'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('sample_esp.txt', header = None, error_bad_lines=False)\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
